:walkthrough: Cloud-Native Integration with EIPs
:che-url: http://che-che.{openshift-app-host}/
:next-lab-url: https://tutorial-web-app-webapp.{openshift-app-host}/tutorial/dayinthelife-streaming.git-labs-04/
:user-password: openshift

ifdef::env-github[]
:next-lab-url: ../lab04/walkthrough.adoc
endif::[]

[id='cloud-native-integration']
= Lab 3 - Cloud-Native Integration with EIPs

In this lab you will consume IoT events from an AMQ Online topic, use Enterprise Integration Patterns (EIPs) in Camel-K to split and route messages to a Datalake.  Lastly, you'll stream the messages to a Standard and Premium Shipping topic on Kafka.

*Audience:* Enterprise Integrators, System Architects, Developers, Data Integrators

*Overview*

Enterprise Integration Patterns (EIPs) have been used in technology for 40+ years.  But are they still relevant when we attempt Cloud-Native integration?

Patterns like the Splitter, Content-Based Routing (CBR) and WireTap are still very useful when it comes to managing and integrating our data in the cloud.  Using Camel-K, we are able to enhance existing streaming technologies like Kafka to help route and mediate our data through various channels.

*Why Red Hat?*

To solve complex cloud-native integration challenges, we need to apply EIPs to manage our data and messaging needs.  Camel-K gives us a Kubernetes native EIP solution for tackling EIPs in the cloud.

By using Camel-K, we can enhance data streaming and apply traditional EIPs to solve cloud-native integration.

*Prerequisites*

This lab assumes you have successfully completed Lab 1 & 2.

*Credentials*

Your username is: `{user-username}` +
Your password is: `{user-password}`

[type=walkthroughResource]
.Che
****
* link:{che-url}/[Open Eclipse Che, window="_blank"]
****

[type=walkthroughResource,serviceName=openshift]
.Openshift
****
* link:{openshift-host}/[Open Console, window="_blank"]
****

[time=5]
[id="provision-amq-topic"]
== Provision AMQ Topic

In this task, you'll provision a messaging topic using Red Hat's Messaging as a Service platform on OpenShift (AMQ Online).

=== Access OpenShift Console

. Navigate to the {openshift-host}[AMQ Online Console, window="_blank", id="{context}-3"]

. Login to using your credentials (`{user-username}` and `{user-password}`).

. Click *amq* listed on the page this will take you to the 
+
image::images/1.1.3-amq-console.png[1.1.3-amq-console, role="integr8ly-img-responsive"]

. Click the *Create Address* button to create the topic.
+
image::images/1.1.7-create-topic.png[1.1.7-create-topic, role="integr8ly-img-responsive"]

. Enter the following details, then click *Next*:
** Name: *`mytopic`*
** Type: *topic*
** Plan: Small Topic
+
image::images/1.1.8-topic-details.png[1.1.8-topic-details, role="integr8ly-img-responsive"]

. Review your configuration and click on Finish
+
image::images/1.1.9-topic-details.png[1.1.9-topic-details, role="integr8ly-img-responsive"]

. Please wait a few minutes for the topic to provision.  Once the queue is provisioned, the topic name (`mytopic`) should have a green checkmark next to it.
+
image::images/1.1.10-topic-provisioned.png[1.1.10-topic-provisioned, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully provision the topic in AMQ Online?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="startup-che-workspace"]
== Provision Eclipse Che Workspace

. Navigate to Eclipse Che console: {che-url}[Eclipse Che, window="_blank", id="{context}-3"]

. Login to Che using your credentials (`{user-username}` and `{user-password}`).
+
image::images/1.1.2-login.png[1.1.2-login, role="integr8ly-img-responsive"]

. Click the **Play** button to open your workspace.  Give it a few minutes to provision and open.
+
image::images/2.1.3-open-workspace.png[2.1.3-open-workspace, role="integr8ly-img-responsive"]

. Once the workspace provisions, click the **Workspace** button and open the `FleurDeLune/projects/harvest/simulator` folder.
+
image::images/2.1.4-che-workspace-folder.png[2.1.4-che-workspace-folder, role="integr8ly-img-responsive"]

. Open the `edge.properties` file.  This is the *application.properties* file where all credentials are stored.  We need to update `remoteURI` for the **AMQP** endpoint.  Copy and paste the `service.host` you copied earlier (into a text editor) and update the `amqp://` endpoint with the correct service hostname.
+
image::images/2.1.5-edge-properties.png[2.1.5-edge-properties, role="integr8ly-img-responsive"]

. Select **Terminal > Open Terminal** in specific container** and select the container that begins with `dil-` (followed by a 5-digit alphanumeric code).  Click it and a terminal window should open.
+
image::images/2.1.6-terminal.png[2.1.6-terminal, role="integr8ly-img-responsive"]

. Navigate back to your OpenShift Admin console and click on your username in the top right-hand corner.  Click **Copy login command**, login with your credentials, then click **Display Token**. Copy the `oc login` command from this page and paste it in your terminal window.  Hit enter to login.
+
image::images/2.1.7-oc.png[2.1.7-oc, role="integr8ly-img-responsive"]

. Once you've logged into OpenShift via the CLI, run the following commands to update `edge-config` configmap.
+
[source,bash,subs="attributes+"]
----
oc project user2
cd /projects/FleurDeLune/projects/harvest/simulator
oc create configmap edge-config  --from-file=edge.properties
----

. Open the `EdgeSimulator.java` file located in the *step-1-simulator* folder.  We want to create a Camel Route that fires a timer every 5 seconds, retrieves some random data, marshalls it to JSON and sends it via AMQP to your AMQ Online **mytopic**.  Copy and paste the following Camel route to your EdgeSimulator.java file:
+
[source,java,subs="attributes+"]
----
from("timer:tick?fixedRate=true&period=5000")
.choice()
    .when(simple("{{simulator.run}}"))
        .setBody(method(this, "genRandomIoTData()"))
        .marshal().json()
        .log("${body}")
        .to("amqp:topic:mytopic?subscriptionDurable=false&exchangePattern=InOnly")
    .otherwise()
        .log("Nothing send ")
;
----
+
image::images/2.1.9-edgesim.png[2.1.9-edgesim, role="integr8ly-img-responsive"]

. Try deploying and running the *EdgeSimulator* Camel-K route by executing the following command
+
[source,bash,subs="attributes+"]
----
kamel run --name edge-simulator EdgeSimulator.java  -d camel-jackson -d camel-bean  --configmap edge-config
----

. Give the deployment 2-5 minutes to run.  Navigate back to the *OpenShift Administrator Console* and verify the **edge-simulator** pod deployed correctly.  You can verify this by checking the Camel **timer** is firing every 5 seconds and there are no errors.
+
image::images/2.1.11-verify-edge-simulator.png[2.1.11-verify-edge-simulator, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully deploy the Camel-K **Edge Simulator** to OpenShift?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="setup-order-inventory"]
== Setup Order Inventory with AMQ Streams

. Navigate to the {openshift-host}[OpenShift Developer Console, window="_blank", id="{context}-3"]

. Login to OpenShift Developer Console using your credentials (`{user-username}` and `{user-password}`).

. Select the *Developer* drop-down, then select *Project: user2*, *+Add* and click on the `From Catalog` link.
+
image::images/3.1.3-add-from-catalog.png[3.1.3-add-from-catalog, role="integr8ly-img-responsive"]

. In the *Filter by keyword...* box, enter `Postgresql`, then select the **PostgreSQL (Ephemeral)** template.  Click the **Instantiate Template** button.
+
image::images/3.1.5-postgres-template.png[3.1.5-postgres-template, role="integr8ly-img-responsive"]

. Update the following template details leaving the remaining default values untouched, then click **Create**:
** PostgreSQL Connection Username: *`user`*
** PostgreSQL Connection Password: *`password`*
+
image::images/3.1.6-postgres-details.png[3.1.6-postgres-details, role="integr8ly-img-responsive"]

. Wait for the pod to deploy (30 seconds - 1 minute).  Click on *Topology* then click the `postgresql` pod.
+
image::images/3.1.7-pod-details.png[3.1.7-pod-details, role="integr8ly-img-responsive"]

. Click on the *Terminal* tab and enter the following:
+
[source,bash,subs="attributes+"]
----
psql -d sampledb -U user

CREATE TABLE premium (
	mmid bigint NOT NULL,
	diameter integer NOT NULL,
    weight decimal NOT NULL,
	created_at TIMESTAMP NOT NULL DEFAULT NOW()
);


CREATE TABLE standard (
	weight decimal NOT NULL,
	created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
INSERT INTO premium(mmid,diameter, weight) VALUES (4567845678456, 4, 2.3);
----

. Now that we've populated the database table with records, navigate back to the *Eclipse Che* window and open the `FleurDeLune/projects/harvest/inventory` project.  Examine the `Inventory.java` file.  At this point we need to create 3 Camel routes.  A route to:
+
** Consume harvest JSON messages from AMQ Online, and using Content-based routing determine whether they are standard, premium or utility marshmallows.
** Insert premium marshmallow dimensions into the PREMIUM database table
** Insert standard marshmallow dimensions into the STANDARD database table

. Copy & paste the following Camel routes to the `Inventory.java` file:
+
[source,java,subs="attributes+"]
----
from("amqp:topic:mytopic?subscriptionDurable=false")
.split().jsonpath("$.harvest[*]")
    .choice()
        .when().jsonpath("$[?(@.diameter > 4 )]" )
            .log("Premium ${body}")
            .wireTap("direct:premiumDB")
                .newExchangeHeader("quality", constant("Premium"))
                .newExchangeHeader("diameter",jsonpath("$.diameter"))
                .newExchangeHeader("weight",jsonpath("$.weight"))
                .newExchangeHeader("mmid",jsonpath("$.mmid"))
            .end()
            .marshal().json()
            .to("kafka:{user-username}-premium?groupId=sender")
        .when().jsonpath("$[?(@.diameter > 1 )]")
            .log("Standard ${body}")
            .wireTap("direct:standardDB")
                .newExchangeHeader("quality", constant("Standard"))
                .newExchangeHeader("weight",jsonpath("$.weight"))
            .end()
            .marshal().json()
            .to("kafka:{user-username}-standard?groupId=sender")
        .otherwise()
            .log("Utility ${body}")
            .marshal().json()
            .to("kafka:{user-username}-utility?groupId=sender")
        .end()
;

from("direct:premiumDB")
    .log("inventoryDa stored ${headers.quality} diameter ${headers.diameter}")
    .setBody(simple("insert into premium (mmid,diameter,weight) VALUES (${headers.mmid},${headers.diameter},${headers.weight} )"))
    .to("jdbc:dataSource");

from("direct:standardDB")
    .log("inventoryDa stored ${headers.quality}")
    .setBody(simple("insert into standard (weight) VALUES (${headers.weight})"))
    .to("jdbc:dataSource");
----
+
image::images/3.1.8-update-inventory-java.png[3.1.8-update-inventory-java, role="integr8ly-img-responsive"]

. Return to the OpenShift Developer console, click **+Add** then click **From Catalog** link.
+
image::images/3.1.3-add-from-catalog.png[3.1.3-add-from-catalog, role="integr8ly-img-responsive"]

. In the filter box type `topic` then select **Kafka topic**.  Click **Create**.  Replace the name `my-topic` with our topic name `{user-username}-premium`, and update the cluster name to `moon`.  Click **Create**.
+
image::images/3.1.9-create-kafka-topic.png[3.1.9-create-kafka-topic, role="integr8ly-img-responsive"]

. Repleat the previous step to create `{user-username}-standard` and `{user-username}-utility` topics.

. Return to the Eclipse Che IDE and open the `kafka.properties` file located in the **step-2-inventory** folder.  Update the **remoteURI** for AMQP with the same one entered in edge.properties.  Additionally, update the **kafka.brokers** URL to be `moon-kafka-bootstrap.{user-username}.svc:9092`.
+
image::images/3.1.10-update-kafka-properties.png[3.1.10-update-kafka-properties, role="integr8ly-img-responsive"]

. Return to the terminal and execute the following commands:
+
[source,bash,subs="attributes+"]
----
oc project user2
cd /projects/FleurDeLune/projects/harvest/inventory
oc create configmap sender-config  --from-file=kafka.properties
kamel run -d mvn:org.postgresql:postgresql:42.2.10 -d camel-jdbc -d mvn:org.apache.commons:commons-dbcp2:2.7.0 --configmap sender-config Inventory.java --dev
----

. After the Camel-K command has finished deploying, it should run via the terminal without errors.
+
image::images/3.1.11-camel-k-inventory.png[3.1.11-camel-k-inventory, role="integr8ly-img-responsive"]

. We can verify that orders are inserted into the database tables (premium and standard), by returning to the OpenShift Developer Console, selecting postgresql and clicking the running pod.
+
image::images/3.1.7-pod-details.png[3.1.7-pod-details, role="integr8ly-img-responsive"]

. Click on the *Terminal* tab and enter the following:
+
[source,bash,subs="attributes+"]
----
psql -d sampledb -U user
----
+
[source,bash,subs="attributes+"]
----
select * from standard;
----

. If the Inventory simulator worked correctly, you should see new rows inserted into the **standard** table.

[type=verification]
Were you able to successfully view records in the **standard** database table?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="setup-data-lake"]
== Setup Data Lake with caching

. Navigate back to the Eclipse Che console, and open `connect-secret.yaml` and `jdg-cluster.yaml` located in `/projects/harvest/shipping`.  Take a  look and notice this will be the identity secret required to setup our Infinispan cluster.
+
image::images/4.1.1-connect-secret.png[4.1.1-connect-secret, role="integr8ly-img-responsive"]

. Lets go ahead and install both the secret and Infinispan cluster (the operator is already running for us).  Via the terminal console, execute the following commands:
+
[source,bash,subs="attributes+"]
----
cd /projects/FleurDeLune/projects/harvest/shipping
oc project user2
oc create -f connect-secret.yaml
oc create -f jdg-cluster.yaml
----

. Navigate back to the OpenShift Developer console, select **Topology*, then click on the `example-infinispan` container.  Verify the pod has started and is running.
+
image::images/4.1.2-check-infinispan.png[4.1.2-check-infinispan, role="integr8ly-img-responsive"]

. Via the Eclipse Che IDE, open the `premiumshipping-config.yaml` file.  Update the `kafka.brokers` and `infinispan-configuration.hosts` URL to match your environment.  The kafka broker URL you can reuse from `kafka-properties` in the `step-2-inventory` folder.  For the infinispan URL, just update the `user1` value to `{user-username}`.
+
image::images/4.1.4-premium-config.png[4.1.4-premium-config, role="integr8ly-img-responsive"]

. Via the terminal, execute the following command to deploy the config map:
+
[source,bash,subs="attributes+"]
----
oc apply -f premiumshipping-config.yaml
----

. Now that we have the config map deployed, let's take a look at `PremiumShipping.java`.  This Class contains a Camel route which consumes messages from Kafka and populates the Infinispan cache with premium shipments. Let's insert our Camel routes into this class:
+
[source,java,subs="attributes+"]
----
from("timer:cleanup?repeatCount=1")
.setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.CLEAR)
.setHeader(InfinispanConstants.KEY).constant("premium")
.to("infinispan:default")
;


from("kafka:user1-premium?groupId=premium-shipping")
.streamCaching()
    .unmarshal(new JacksonDataFormat(Map.class))
    .log("Input --> ${body}")
    .setHeader("marshmallow").simple("${body}")
    .setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.GET)
    .setHeader(InfinispanConstants.KEY).constant("premium")
    .to("infinispan:default")
    .setHeader(InfinispanConstants.OPERATION).constant(InfinispanOperation.PUT)
    .setHeader(InfinispanConstants.KEY).constant("premium")
    .setHeader(InfinispanConstants.VALUE).method(this, "assignShipment(${body}, ${header.marshmallow})")
    .log("${body}")
    .to("infinispan:default")

;
----
+
image::images/4.1.6-update-kafka-topic.png[4.1.6-update-kafka-topic, role="integr8ly-img-responsive"]

. We need to update the standard shipping config map.  Open up `standardshipping-config.yaml` file and update both the `kafka.brokers` and `infinispan.configuration.hosts` URLs.  You can reuse the URLs you used in the premium shipping config map.
+
image::images/4.1.7-update-standard-config.png[4.1.7-update-standard-config, role="integr8ly-img-responsive"]

. Via the terminal, execute the following command to deploy the config map:
+
[source,bash,subs="attributes+"]
----
oc apply -f standardshipping-config.yaml
----

. Now that we have the config map deployed, let's take a look at `StandardShipping.java`.  This Class contains a Camel route which consumes messages from Kafka and populates the Infinispan cache with standard shipments. Update the kafka topic name to `{user-username}-standard`.
+
image::images/4.1.8-standard-java-update.png[4.1.8-standard-java-update, role="integr8ly-img-responsive"]

. Now that we have updated all the config files and code, we need to test our Camel-K routes.  Return to the terminal and execute the following command:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-jackson -d mvn:org.wildfly.security:wildfly-elytron:1.11.2.Final --configmap premiumshipping-config PremiumShipping.java --dev
----

. Ensure that the Camel-K command ran without error and connections to Infinispan and Kafka were successful.  You can use *Ctrl-C* to terminate the Camel-K process.  Repeat the same for the StandardShipping flow:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-jackson -d mvn:org.wildfly.security:wildfly-elytron:1.11.2.Final --configmap standardshipping-config StandardShipping.java --dev
----

[type=verification]
Were you able to successfully execute both the Standard and Premium shipping Camel-K routes without error?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=15]
[id="setup-supply-console"]
== Create a Shipping Console

Now that we have our backend services running, we can focus on creating a Shipping Console UI.

=== Deploy RESTful Interface

.  First step is to update the `/projects/harvest/display/shippingconsole-config.yaml` config map with the correct InfiniSpan hostname.  Find  **camel.component.infinispan.configuration.hosts** and update the service to: `example-infinispan.{user-username}.svc:11222`.
+
image::images/5.1.1-config-map.png[5.1.1-config-map, role="integr8ly-img-responsive"]

. Add the config map to OpenShift using the following command (via the terminal):
+
[source,bash,subs="attributes+"]
----
cd /projects/FleurDeLune/projects/harvest/display/
oc project user2
oc apply -f shippingconsole-config.yaml
----

. Now that we have the configmap updated, take a look at **ConsoleService.java**.  Notice that we use Camel RESTDsl to expose a bunch of RESTFul queries around our infinispan cache.  Let's try running this interface using the following command:
+
[source,bash,subs="attributes+"]
----
kamel run -d camel-infinispan -d camel-bean -d camel-swagger-java -d camel-jackson -d camel-undertow  --configmap shippingconsole-config ConsoleService.java --dev
----

. Now that we have the Camel-K interface running, we can view the content in our Data Lake.  First, navigate here to see the Standard shipments: `http://console-service-{user-username}.{openshift-app-host}/standard` and here for our Premium shipments: `http://console-service-{user-username}.{openshift-app-host}/premium`.

== Setup Grafana Dashboard

. First of all, we need to deploy the Grafana template to our namespace.  Execute the following command via the CLI terminal:
+
[source,bash,subs="attributes+"]
----
oc apply -f grafana.yaml
----
+
[source,bash,subs="attributes+"]
----
oc expose svc grafana
----

. Now that we have Grafana running, navigate back to the OpenShift Administrator console and select **Networking > Routes**.  Select the *Grafana* route.
+
image::images/6.1.1-grafana-route.png[6.1.1-grafana-route, role="integr8ly-img-responsive"]

. Login to Grafana using the credentials `admin/admin`.  If prompted to change your password, set it back to `admin` again.

. Now that you are logged into Grafana, we need to create a datasource. Click the `Create your first data source link`, then select **PostgreSQL**.
+
image::images/6.1.3-select-datasource.png[6.1.3-select-datasource, role="integr8ly-img-responsive"]

. In the DataSource entry screen, enter the following:
** Name: *`SampleDB`*
** Host: *`postgresql:5432`*
** Database: *`sampledb`*
** User: *`user`*
** Password: *`password`*
** SSL Mode: *`disable`*

. Click **Save & Test**
+
image::images/6.1.4-postgres-save.png[6.1.4-postgres-save, role="integr8ly-img-responsive"]

. Click the **+** symbol then click **Import**.  Give the dashboard a name of `FleurDeLune`.  Navigate back to Eclipse Che and copy the content from `/projects/harvest/display/FleurDeLune-Dashboard.json`.  Paste the content into the Grafana JSON window then click **Load**.
+
image::images/6.1.5-load-json.png[6.1.5-load-json, role="integr8ly-img-responsive"]

. If everything has been running correctly, you should see some Marshmallow distribution and weight metrics displayed on your graph.
+
image::images/6.1.6-graph-metrics.png[6.1.6-graph-metrics, role="integr8ly-img-responsive"]

[type=verification]
Were you able to successfully view the FleurDeLune metrics?

[type=verificationFail]
Verify that you followed each step in the procedure above. If you are still having issues, contact your administrator.

[time=5]
[id="summary"]
== Summary

In this lab you exposed inventory data via RestDSL, cached data from a Data Lake using InfiniSpan, then graphed the results using live data metrics in Grafana.

Open source connectors enable integrations with your local systems landscape. Explore InfiniSpan, Camel-K, and Grafana to connect APIs and services for event-driven application architectures (EDA). Red Hat offers supported versions of these connectors via Fuse and DataGrid.

You can now proceed to link:{next-lab-url}[Lab 4].

[time=4]
[id="further-reading"]
== Notes and Further Reading

* https://www.redhat.com/en/technologies/jboss-middleware/amq[Red Hat AMQ]
* https://developers.redhat.com/topics/event-driven/connectors/[Camel & Debezium Connectors]
